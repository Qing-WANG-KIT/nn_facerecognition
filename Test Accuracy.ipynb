{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import os\n",
    "import torch.utils.data\n",
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "\n",
    "# 针对LFW测试集数据加载\n",
    "\n",
    "class LFW(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None):\n",
    "        self.root = root\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.nameLs = []\n",
    "        self.nameRs = []\n",
    "        self.folds = []\n",
    "        self.flags = []\n",
    "        # 读取pairs文件\n",
    "        with open(file_list) as f:\n",
    "            pairs = f.read().splitlines()[1:]\n",
    "        # 将路径存储\n",
    "        for i, p in enumerate(pairs):\n",
    "            p = p.split('\\t')\n",
    "            if len(p) == 3: # 相同\n",
    "                nameL = p[0] + '/' + p[0] + '_' + '{:04}.jpg'.format(int(p[1]))\n",
    "                nameR = p[0] + '/' + p[0] + '_' + '{:04}.jpg'.format(int(p[2]))\n",
    "                fold = i // 600 # 分十组\n",
    "                flag = 1 # 相同\n",
    "            elif len(p) == 4: # 不同\n",
    "                nameL = p[0] + '/' + p[0] + '_' + '{:04}.jpg'.format(int(p[1]))\n",
    "                nameR = p[2] + '/' + p[2] + '_' + '{:04}.jpg'.format(int(p[3]))\n",
    "                fold = i // 600\n",
    "                flag = -1 # 不同\n",
    "            self.nameLs.append(nameL)\n",
    "            self.nameRs.append(nameR)\n",
    "            self.folds.append(fold)\n",
    "            self.flags.append(flag)\n",
    "    def __getitem__(self, index):\n",
    "        img_l = Image.open(os.path.join(self.root, self.nameLs[index])) # 读取第一张图\n",
    "        img_r = Image.open(os.path.join(self.root, self.nameRs[index])) # 读取第二张图\n",
    "        imglist = [img_l, img_l.transpose(Image.FLIP_LEFT_RIGHT), img_r, img_r.transpose(Image.FLIP_LEFT_RIGHT)] # 翻转拼接\n",
    "        # 图片预处理\n",
    "        if self.transform is not None:\n",
    "            for i in range(len(imglist)):\n",
    "                imglist[i] = self.transform(imglist[i])\n",
    "            imgs = imglist\n",
    "            return imgs\n",
    "        else:\n",
    "            imgs = [torch.from_numpy(i) for i in imglist]\n",
    "            return imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nameLs)\n",
    "    \n",
    "# 求准确率\n",
    "def getAccuracy(scores, flags, threshold):\n",
    "    p = np.sum(scores[flags == 1] > threshold)\n",
    "    n = np.sum(scores[flags == -1] < threshold)\n",
    "    return 1.0 * (p + n) / len(scores)\n",
    "\n",
    "# 0-1分成thrnum份，10000个阈值每次求准确率，去准确率最高的一个阈值\n",
    "def getThreshold(scores, flags, thrNum):\n",
    "    accuracys = np.zeros((thrNum + 1, 1))\n",
    "    thresholds = np.arange(0, thrNum + 1) * 1.0 / thrNum\n",
    "    for i in range(thrNum + 1):\n",
    "        accuracys[i] = getAccuracy(scores, flags, thresholds[i])\n",
    "    max_index = np.squeeze(accuracys == np.max(accuracys))\n",
    "    bestThreshold = np.mean(thresholds[max_index])\n",
    "    return bestThreshold\n",
    "\n",
    "# 评估\n",
    "def evaluation_10_fold(feature_path):\n",
    "    ACCs = np.zeros(10)\n",
    "    result = scipy.io.loadmat(feature_path)\n",
    "    # 读取文件\n",
    "    fold = result['fold']\n",
    "    flags = result['flag']\n",
    "    featureLs = result['fl']  # (6000,256)\n",
    "    featureRs = result['fr']  # (6000,256)\n",
    "    flags = np.squeeze(flags)\n",
    "    # 得分 cos(theta)\n",
    "    featureLs = featureLs / np.expand_dims(np.sqrt(np.sum(np.power(featureLs, 2), 1)), 1)\n",
    "    featureRs = featureRs / np.expand_dims(np.sqrt(np.sum(np.power(featureRs, 2), 1)), 1)\n",
    "    scores = np.sum(np.multiply(featureLs, featureRs), 1)\n",
    "    # 得到阈值\n",
    "    threshold = getThreshold(scores, flags, 10000)\n",
    "    # 得到准确率\n",
    "    for i in range(10):\n",
    "        testFold = fold == i\n",
    "        ACCs[i] = getAccuracy(scores[testFold[0]], flags[testFold[0]], threshold)\n",
    "    return ACCs\n",
    "\n",
    "# 保存特征\n",
    "def getFeatureFromTorch(feature_save_dir, model, device, data_set, data_loader):\n",
    "    featureLs = None\n",
    "    featureRs = None\n",
    "    count = 0\n",
    "    for data in data_loader:\n",
    "        for i in range(len(data)): # data存有四张图片\n",
    "            data[i] = data[i].to(device)\n",
    "        count += data[0].size(0)\n",
    "        print('extracing deep features from the face pair {}...'.format(count))\n",
    "        with torch.no_grad():\n",
    "            res = [model(d).data.cpu().numpy() for d in data]\n",
    "        featureL = np.concatenate((res[0], res[1]), 1)\n",
    "        featureR = np.concatenate((res[2], res[3]), 1)\n",
    "        if featureLs is None:\n",
    "            featureLs = featureL\n",
    "        else:\n",
    "            featureLs = np.concatenate((featureLs, featureL), 0)\n",
    "        if featureRs is None:\n",
    "            featureRs = featureR\n",
    "        else:\n",
    "            featureRs = np.concatenate((featureRs, featureR), 0)\n",
    "    # 保存\n",
    "    result = {'fl': featureLs, 'fr': featureRs, 'fold': data_set.folds, 'flag': data_set.flags}\n",
    "    scipy.io.savemat(feature_save_dir, result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Accuracy(model_path):\n",
    "    data_root = r'C:\\Users\\123\\Desktop\\数据集仓库\\lfw'\n",
    "    file_list='./data/pairs.txt'\n",
    "    feature_save_dir='./results/result_res.mat'\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "    data_transforms = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=mean,std=std),\n",
    "        ])\n",
    "    # 加载模型2\n",
    "    model=torch.load(model_path)\n",
    "\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    lfw_dataset = LFW(data_root, file_list, transform=data_transforms)\n",
    "    lfw_loader = torch.utils.data.DataLoader(lfw_dataset, batch_size=64,\n",
    "                                                 shuffle=False, num_workers=0, drop_last=False)\n",
    "\n",
    "     # 保存特征\n",
    "    getFeatureFromTorch(feature_save_dir=feature_save_dir, model=model, device=device, data_set=lfw_dataset, data_loader=lfw_loader) # 保存特征\n",
    "    ACCs = evaluation_10_fold(feature_save_dir) # 计算\n",
    "    \n",
    "    for i in range(len(ACCs)):\n",
    "        print('{}    {:.2f}%'.format(i+1, ACCs[i] * 100))\n",
    "    print('--------')\n",
    "    print('AVE    {:.4f}%'.format(np.mean(ACCs) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracing deep features from the face pair 64...\n",
      "extracing deep features from the face pair 128...\n",
      "extracing deep features from the face pair 192...\n",
      "extracing deep features from the face pair 256...\n",
      "extracing deep features from the face pair 320...\n",
      "extracing deep features from the face pair 384...\n",
      "extracing deep features from the face pair 448...\n",
      "extracing deep features from the face pair 512...\n",
      "extracing deep features from the face pair 576...\n",
      "extracing deep features from the face pair 640...\n",
      "extracing deep features from the face pair 704...\n",
      "extracing deep features from the face pair 768...\n",
      "extracing deep features from the face pair 832...\n",
      "extracing deep features from the face pair 896...\n",
      "extracing deep features from the face pair 960...\n",
      "extracing deep features from the face pair 1024...\n",
      "extracing deep features from the face pair 1088...\n",
      "extracing deep features from the face pair 1152...\n",
      "extracing deep features from the face pair 1216...\n",
      "extracing deep features from the face pair 1280...\n",
      "extracing deep features from the face pair 1344...\n",
      "extracing deep features from the face pair 1408...\n",
      "extracing deep features from the face pair 1472...\n",
      "extracing deep features from the face pair 1536...\n",
      "extracing deep features from the face pair 1600...\n",
      "extracing deep features from the face pair 1664...\n",
      "extracing deep features from the face pair 1728...\n",
      "extracing deep features from the face pair 1792...\n",
      "extracing deep features from the face pair 1856...\n",
      "extracing deep features from the face pair 1920...\n",
      "extracing deep features from the face pair 1984...\n",
      "extracing deep features from the face pair 2048...\n",
      "extracing deep features from the face pair 2112...\n",
      "extracing deep features from the face pair 2176...\n",
      "extracing deep features from the face pair 2240...\n",
      "extracing deep features from the face pair 2304...\n",
      "extracing deep features from the face pair 2368...\n",
      "extracing deep features from the face pair 2432...\n",
      "extracing deep features from the face pair 2496...\n",
      "extracing deep features from the face pair 2560...\n",
      "extracing deep features from the face pair 2624...\n",
      "extracing deep features from the face pair 2688...\n",
      "extracing deep features from the face pair 2752...\n",
      "extracing deep features from the face pair 2816...\n",
      "extracing deep features from the face pair 2880...\n",
      "extracing deep features from the face pair 2944...\n",
      "extracing deep features from the face pair 3008...\n",
      "extracing deep features from the face pair 3072...\n",
      "extracing deep features from the face pair 3136...\n",
      "extracing deep features from the face pair 3200...\n",
      "extracing deep features from the face pair 3264...\n",
      "extracing deep features from the face pair 3328...\n",
      "extracing deep features from the face pair 3392...\n",
      "extracing deep features from the face pair 3456...\n",
      "extracing deep features from the face pair 3520...\n",
      "extracing deep features from the face pair 3584...\n",
      "extracing deep features from the face pair 3648...\n",
      "extracing deep features from the face pair 3712...\n",
      "extracing deep features from the face pair 3776...\n",
      "extracing deep features from the face pair 3840...\n",
      "extracing deep features from the face pair 3904...\n",
      "extracing deep features from the face pair 3968...\n",
      "extracing deep features from the face pair 4032...\n",
      "extracing deep features from the face pair 4096...\n",
      "extracing deep features from the face pair 4160...\n",
      "extracing deep features from the face pair 4224...\n",
      "extracing deep features from the face pair 4288...\n",
      "extracing deep features from the face pair 4352...\n",
      "extracing deep features from the face pair 4416...\n",
      "extracing deep features from the face pair 4480...\n",
      "extracing deep features from the face pair 4544...\n",
      "extracing deep features from the face pair 4608...\n",
      "extracing deep features from the face pair 4672...\n",
      "extracing deep features from the face pair 4736...\n",
      "extracing deep features from the face pair 4800...\n",
      "extracing deep features from the face pair 4864...\n",
      "extracing deep features from the face pair 4928...\n",
      "extracing deep features from the face pair 4992...\n",
      "extracing deep features from the face pair 5056...\n",
      "extracing deep features from the face pair 5120...\n",
      "extracing deep features from the face pair 5184...\n",
      "extracing deep features from the face pair 5248...\n",
      "extracing deep features from the face pair 5312...\n",
      "extracing deep features from the face pair 5376...\n",
      "extracing deep features from the face pair 5440...\n",
      "extracing deep features from the face pair 5504...\n",
      "extracing deep features from the face pair 5568...\n",
      "extracing deep features from the face pair 5632...\n",
      "extracing deep features from the face pair 5696...\n",
      "extracing deep features from the face pair 5760...\n",
      "extracing deep features from the face pair 5824...\n",
      "extracing deep features from the face pair 5888...\n",
      "extracing deep features from the face pair 5952...\n",
      "extracing deep features from the face pair 6000...\n",
      "1    66.83%\n",
      "2    66.33%\n",
      "3    66.67%\n",
      "4    68.50%\n",
      "5    66.17%\n",
      "6    69.50%\n",
      "7    66.33%\n",
      "8    68.33%\n",
      "9    65.50%\n",
      "10    65.17%\n",
      "--------\n",
      "AVE    66.9333%\n"
     ]
    }
   ],
   "source": [
    "test_Accuracy('./model/Training_1_Res_NLLLoss_2FC_200e.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracing deep features from the face pair 64...\n",
      "extracing deep features from the face pair 128...\n",
      "extracing deep features from the face pair 192...\n",
      "extracing deep features from the face pair 256...\n",
      "extracing deep features from the face pair 320...\n",
      "extracing deep features from the face pair 384...\n",
      "extracing deep features from the face pair 448...\n",
      "extracing deep features from the face pair 512...\n",
      "extracing deep features from the face pair 576...\n",
      "extracing deep features from the face pair 640...\n",
      "extracing deep features from the face pair 704...\n",
      "extracing deep features from the face pair 768...\n",
      "extracing deep features from the face pair 832...\n",
      "extracing deep features from the face pair 896...\n",
      "extracing deep features from the face pair 960...\n",
      "extracing deep features from the face pair 1024...\n",
      "extracing deep features from the face pair 1088...\n",
      "extracing deep features from the face pair 1152...\n",
      "extracing deep features from the face pair 1216...\n",
      "extracing deep features from the face pair 1280...\n",
      "extracing deep features from the face pair 1344...\n",
      "extracing deep features from the face pair 1408...\n",
      "extracing deep features from the face pair 1472...\n",
      "extracing deep features from the face pair 1536...\n",
      "extracing deep features from the face pair 1600...\n",
      "extracing deep features from the face pair 1664...\n",
      "extracing deep features from the face pair 1728...\n",
      "extracing deep features from the face pair 1792...\n",
      "extracing deep features from the face pair 1856...\n",
      "extracing deep features from the face pair 1920...\n",
      "extracing deep features from the face pair 1984...\n",
      "extracing deep features from the face pair 2048...\n",
      "extracing deep features from the face pair 2112...\n",
      "extracing deep features from the face pair 2176...\n",
      "extracing deep features from the face pair 2240...\n",
      "extracing deep features from the face pair 2304...\n",
      "extracing deep features from the face pair 2368...\n",
      "extracing deep features from the face pair 2432...\n",
      "extracing deep features from the face pair 2496...\n",
      "extracing deep features from the face pair 2560...\n",
      "extracing deep features from the face pair 2624...\n",
      "extracing deep features from the face pair 2688...\n",
      "extracing deep features from the face pair 2752...\n",
      "extracing deep features from the face pair 2816...\n",
      "extracing deep features from the face pair 2880...\n",
      "extracing deep features from the face pair 2944...\n",
      "extracing deep features from the face pair 3008...\n",
      "extracing deep features from the face pair 3072...\n",
      "extracing deep features from the face pair 3136...\n",
      "extracing deep features from the face pair 3200...\n",
      "extracing deep features from the face pair 3264...\n",
      "extracing deep features from the face pair 3328...\n",
      "extracing deep features from the face pair 3392...\n",
      "extracing deep features from the face pair 3456...\n",
      "extracing deep features from the face pair 3520...\n",
      "extracing deep features from the face pair 3584...\n",
      "extracing deep features from the face pair 3648...\n",
      "extracing deep features from the face pair 3712...\n",
      "extracing deep features from the face pair 3776...\n",
      "extracing deep features from the face pair 3840...\n",
      "extracing deep features from the face pair 3904...\n",
      "extracing deep features from the face pair 3968...\n",
      "extracing deep features from the face pair 4032...\n",
      "extracing deep features from the face pair 4096...\n",
      "extracing deep features from the face pair 4160...\n",
      "extracing deep features from the face pair 4224...\n",
      "extracing deep features from the face pair 4288...\n",
      "extracing deep features from the face pair 4352...\n",
      "extracing deep features from the face pair 4416...\n",
      "extracing deep features from the face pair 4480...\n",
      "extracing deep features from the face pair 4544...\n",
      "extracing deep features from the face pair 4608...\n",
      "extracing deep features from the face pair 4672...\n",
      "extracing deep features from the face pair 4736...\n",
      "extracing deep features from the face pair 4800...\n",
      "extracing deep features from the face pair 4864...\n",
      "extracing deep features from the face pair 4928...\n",
      "extracing deep features from the face pair 4992...\n",
      "extracing deep features from the face pair 5056...\n",
      "extracing deep features from the face pair 5120...\n",
      "extracing deep features from the face pair 5184...\n",
      "extracing deep features from the face pair 5248...\n",
      "extracing deep features from the face pair 5312...\n",
      "extracing deep features from the face pair 5376...\n",
      "extracing deep features from the face pair 5440...\n",
      "extracing deep features from the face pair 5504...\n",
      "extracing deep features from the face pair 5568...\n",
      "extracing deep features from the face pair 5632...\n",
      "extracing deep features from the face pair 5696...\n",
      "extracing deep features from the face pair 5760...\n",
      "extracing deep features from the face pair 5824...\n",
      "extracing deep features from the face pair 5888...\n",
      "extracing deep features from the face pair 5952...\n",
      "extracing deep features from the face pair 6000...\n",
      "1    71.50%\n",
      "2    70.33%\n",
      "3    69.50%\n",
      "4    66.67%\n",
      "5    71.67%\n",
      "6    69.33%\n",
      "7    70.67%\n",
      "8    72.00%\n",
      "9    68.67%\n",
      "10    67.67%\n",
      "--------\n",
      "AVE    69.8000%\n"
     ]
    }
   ],
   "source": [
    "test_Accuracy('./model/Training_2_Res_NLLLoss_1FC_50e.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracing deep features from the face pair 64...\n",
      "extracing deep features from the face pair 128...\n",
      "extracing deep features from the face pair 192...\n",
      "extracing deep features from the face pair 256...\n",
      "extracing deep features from the face pair 320...\n",
      "extracing deep features from the face pair 384...\n",
      "extracing deep features from the face pair 448...\n",
      "extracing deep features from the face pair 512...\n",
      "extracing deep features from the face pair 576...\n",
      "extracing deep features from the face pair 640...\n",
      "extracing deep features from the face pair 704...\n",
      "extracing deep features from the face pair 768...\n",
      "extracing deep features from the face pair 832...\n",
      "extracing deep features from the face pair 896...\n",
      "extracing deep features from the face pair 960...\n",
      "extracing deep features from the face pair 1024...\n",
      "extracing deep features from the face pair 1088...\n",
      "extracing deep features from the face pair 1152...\n",
      "extracing deep features from the face pair 1216...\n",
      "extracing deep features from the face pair 1280...\n",
      "extracing deep features from the face pair 1344...\n",
      "extracing deep features from the face pair 1408...\n",
      "extracing deep features from the face pair 1472...\n",
      "extracing deep features from the face pair 1536...\n",
      "extracing deep features from the face pair 1600...\n",
      "extracing deep features from the face pair 1664...\n",
      "extracing deep features from the face pair 1728...\n",
      "extracing deep features from the face pair 1792...\n",
      "extracing deep features from the face pair 1856...\n",
      "extracing deep features from the face pair 1920...\n",
      "extracing deep features from the face pair 1984...\n",
      "extracing deep features from the face pair 2048...\n",
      "extracing deep features from the face pair 2112...\n",
      "extracing deep features from the face pair 2176...\n",
      "extracing deep features from the face pair 2240...\n",
      "extracing deep features from the face pair 2304...\n",
      "extracing deep features from the face pair 2368...\n",
      "extracing deep features from the face pair 2432...\n",
      "extracing deep features from the face pair 2496...\n",
      "extracing deep features from the face pair 2560...\n",
      "extracing deep features from the face pair 2624...\n",
      "extracing deep features from the face pair 2688...\n",
      "extracing deep features from the face pair 2752...\n",
      "extracing deep features from the face pair 2816...\n",
      "extracing deep features from the face pair 2880...\n",
      "extracing deep features from the face pair 2944...\n",
      "extracing deep features from the face pair 3008...\n",
      "extracing deep features from the face pair 3072...\n",
      "extracing deep features from the face pair 3136...\n",
      "extracing deep features from the face pair 3200...\n",
      "extracing deep features from the face pair 3264...\n",
      "extracing deep features from the face pair 3328...\n",
      "extracing deep features from the face pair 3392...\n",
      "extracing deep features from the face pair 3456...\n",
      "extracing deep features from the face pair 3520...\n",
      "extracing deep features from the face pair 3584...\n",
      "extracing deep features from the face pair 3648...\n",
      "extracing deep features from the face pair 3712...\n",
      "extracing deep features from the face pair 3776...\n",
      "extracing deep features from the face pair 3840...\n",
      "extracing deep features from the face pair 3904...\n",
      "extracing deep features from the face pair 3968...\n",
      "extracing deep features from the face pair 4032...\n",
      "extracing deep features from the face pair 4096...\n",
      "extracing deep features from the face pair 4160...\n",
      "extracing deep features from the face pair 4224...\n",
      "extracing deep features from the face pair 4288...\n",
      "extracing deep features from the face pair 4352...\n",
      "extracing deep features from the face pair 4416...\n",
      "extracing deep features from the face pair 4480...\n",
      "extracing deep features from the face pair 4544...\n",
      "extracing deep features from the face pair 4608...\n",
      "extracing deep features from the face pair 4672...\n",
      "extracing deep features from the face pair 4736...\n",
      "extracing deep features from the face pair 4800...\n",
      "extracing deep features from the face pair 4864...\n",
      "extracing deep features from the face pair 4928...\n",
      "extracing deep features from the face pair 4992...\n",
      "extracing deep features from the face pair 5056...\n",
      "extracing deep features from the face pair 5120...\n",
      "extracing deep features from the face pair 5184...\n",
      "extracing deep features from the face pair 5248...\n",
      "extracing deep features from the face pair 5312...\n",
      "extracing deep features from the face pair 5376...\n",
      "extracing deep features from the face pair 5440...\n",
      "extracing deep features from the face pair 5504...\n",
      "extracing deep features from the face pair 5568...\n",
      "extracing deep features from the face pair 5632...\n",
      "extracing deep features from the face pair 5696...\n",
      "extracing deep features from the face pair 5760...\n",
      "extracing deep features from the face pair 5824...\n",
      "extracing deep features from the face pair 5888...\n",
      "extracing deep features from the face pair 5952...\n",
      "extracing deep features from the face pair 6000...\n",
      "1    69.67%\n",
      "2    70.50%\n",
      "3    69.17%\n",
      "4    66.67%\n",
      "5    71.33%\n",
      "6    69.50%\n",
      "7    69.83%\n",
      "8    72.50%\n",
      "9    68.83%\n",
      "10    69.17%\n",
      "--------\n",
      "AVE    69.7167%\n"
     ]
    }
   ],
   "source": [
    "test_Accuracy('./model/Training_3_Res_FocalLoss_1FC_50e.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracing deep features from the face pair 64...\n",
      "extracing deep features from the face pair 128...\n",
      "extracing deep features from the face pair 192...\n",
      "extracing deep features from the face pair 256...\n",
      "extracing deep features from the face pair 320...\n",
      "extracing deep features from the face pair 384...\n",
      "extracing deep features from the face pair 448...\n",
      "extracing deep features from the face pair 512...\n",
      "extracing deep features from the face pair 576...\n",
      "extracing deep features from the face pair 640...\n",
      "extracing deep features from the face pair 704...\n",
      "extracing deep features from the face pair 768...\n",
      "extracing deep features from the face pair 832...\n",
      "extracing deep features from the face pair 896...\n",
      "extracing deep features from the face pair 960...\n",
      "extracing deep features from the face pair 1024...\n",
      "extracing deep features from the face pair 1088...\n",
      "extracing deep features from the face pair 1152...\n",
      "extracing deep features from the face pair 1216...\n",
      "extracing deep features from the face pair 1280...\n",
      "extracing deep features from the face pair 1344...\n",
      "extracing deep features from the face pair 1408...\n",
      "extracing deep features from the face pair 1472...\n",
      "extracing deep features from the face pair 1536...\n",
      "extracing deep features from the face pair 1600...\n",
      "extracing deep features from the face pair 1664...\n",
      "extracing deep features from the face pair 1728...\n",
      "extracing deep features from the face pair 1792...\n",
      "extracing deep features from the face pair 1856...\n",
      "extracing deep features from the face pair 1920...\n",
      "extracing deep features from the face pair 1984...\n",
      "extracing deep features from the face pair 2048...\n",
      "extracing deep features from the face pair 2112...\n",
      "extracing deep features from the face pair 2176...\n",
      "extracing deep features from the face pair 2240...\n",
      "extracing deep features from the face pair 2304...\n",
      "extracing deep features from the face pair 2368...\n",
      "extracing deep features from the face pair 2432...\n",
      "extracing deep features from the face pair 2496...\n",
      "extracing deep features from the face pair 2560...\n",
      "extracing deep features from the face pair 2624...\n",
      "extracing deep features from the face pair 2688...\n",
      "extracing deep features from the face pair 2752...\n",
      "extracing deep features from the face pair 2816...\n",
      "extracing deep features from the face pair 2880...\n",
      "extracing deep features from the face pair 2944...\n",
      "extracing deep features from the face pair 3008...\n",
      "extracing deep features from the face pair 3072...\n",
      "extracing deep features from the face pair 3136...\n",
      "extracing deep features from the face pair 3200...\n",
      "extracing deep features from the face pair 3264...\n",
      "extracing deep features from the face pair 3328...\n",
      "extracing deep features from the face pair 3392...\n",
      "extracing deep features from the face pair 3456...\n",
      "extracing deep features from the face pair 3520...\n",
      "extracing deep features from the face pair 3584...\n",
      "extracing deep features from the face pair 3648...\n",
      "extracing deep features from the face pair 3712...\n",
      "extracing deep features from the face pair 3776...\n",
      "extracing deep features from the face pair 3840...\n",
      "extracing deep features from the face pair 3904...\n",
      "extracing deep features from the face pair 3968...\n",
      "extracing deep features from the face pair 4032...\n",
      "extracing deep features from the face pair 4096...\n",
      "extracing deep features from the face pair 4160...\n",
      "extracing deep features from the face pair 4224...\n",
      "extracing deep features from the face pair 4288...\n",
      "extracing deep features from the face pair 4352...\n",
      "extracing deep features from the face pair 4416...\n",
      "extracing deep features from the face pair 4480...\n",
      "extracing deep features from the face pair 4544...\n",
      "extracing deep features from the face pair 4608...\n",
      "extracing deep features from the face pair 4672...\n",
      "extracing deep features from the face pair 4736...\n",
      "extracing deep features from the face pair 4800...\n",
      "extracing deep features from the face pair 4864...\n",
      "extracing deep features from the face pair 4928...\n",
      "extracing deep features from the face pair 4992...\n",
      "extracing deep features from the face pair 5056...\n",
      "extracing deep features from the face pair 5120...\n",
      "extracing deep features from the face pair 5184...\n",
      "extracing deep features from the face pair 5248...\n",
      "extracing deep features from the face pair 5312...\n",
      "extracing deep features from the face pair 5376...\n",
      "extracing deep features from the face pair 5440...\n",
      "extracing deep features from the face pair 5504...\n",
      "extracing deep features from the face pair 5568...\n",
      "extracing deep features from the face pair 5632...\n",
      "extracing deep features from the face pair 5696...\n",
      "extracing deep features from the face pair 5760...\n",
      "extracing deep features from the face pair 5824...\n",
      "extracing deep features from the face pair 5888...\n",
      "extracing deep features from the face pair 5952...\n",
      "extracing deep features from the face pair 6000...\n",
      "1    71.50%\n",
      "2    70.33%\n",
      "3    69.50%\n",
      "4    66.67%\n",
      "5    71.67%\n",
      "6    69.33%\n",
      "7    70.67%\n",
      "8    72.00%\n",
      "9    68.67%\n",
      "10    67.67%\n",
      "--------\n",
      "AVE    69.8000%\n"
     ]
    }
   ],
   "source": [
    "test_Accuracy('./model/Training_4_Res_NLLLoss_1FC_100e.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracing deep features from the face pair 64...\n",
      "extracing deep features from the face pair 128...\n",
      "extracing deep features from the face pair 192...\n",
      "extracing deep features from the face pair 256...\n",
      "extracing deep features from the face pair 320...\n",
      "extracing deep features from the face pair 384...\n",
      "extracing deep features from the face pair 448...\n",
      "extracing deep features from the face pair 512...\n",
      "extracing deep features from the face pair 576...\n",
      "extracing deep features from the face pair 640...\n",
      "extracing deep features from the face pair 704...\n",
      "extracing deep features from the face pair 768...\n",
      "extracing deep features from the face pair 832...\n",
      "extracing deep features from the face pair 896...\n",
      "extracing deep features from the face pair 960...\n",
      "extracing deep features from the face pair 1024...\n",
      "extracing deep features from the face pair 1088...\n",
      "extracing deep features from the face pair 1152...\n",
      "extracing deep features from the face pair 1216...\n",
      "extracing deep features from the face pair 1280...\n",
      "extracing deep features from the face pair 1344...\n",
      "extracing deep features from the face pair 1408...\n",
      "extracing deep features from the face pair 1472...\n",
      "extracing deep features from the face pair 1536...\n",
      "extracing deep features from the face pair 1600...\n",
      "extracing deep features from the face pair 1664...\n",
      "extracing deep features from the face pair 1728...\n",
      "extracing deep features from the face pair 1792...\n",
      "extracing deep features from the face pair 1856...\n",
      "extracing deep features from the face pair 1920...\n",
      "extracing deep features from the face pair 1984...\n",
      "extracing deep features from the face pair 2048...\n",
      "extracing deep features from the face pair 2112...\n",
      "extracing deep features from the face pair 2176...\n",
      "extracing deep features from the face pair 2240...\n",
      "extracing deep features from the face pair 2304...\n",
      "extracing deep features from the face pair 2368...\n",
      "extracing deep features from the face pair 2432...\n",
      "extracing deep features from the face pair 2496...\n",
      "extracing deep features from the face pair 2560...\n",
      "extracing deep features from the face pair 2624...\n",
      "extracing deep features from the face pair 2688...\n",
      "extracing deep features from the face pair 2752...\n",
      "extracing deep features from the face pair 2816...\n",
      "extracing deep features from the face pair 2880...\n",
      "extracing deep features from the face pair 2944...\n",
      "extracing deep features from the face pair 3008...\n",
      "extracing deep features from the face pair 3072...\n",
      "extracing deep features from the face pair 3136...\n",
      "extracing deep features from the face pair 3200...\n",
      "extracing deep features from the face pair 3264...\n",
      "extracing deep features from the face pair 3328...\n",
      "extracing deep features from the face pair 3392...\n",
      "extracing deep features from the face pair 3456...\n",
      "extracing deep features from the face pair 3520...\n",
      "extracing deep features from the face pair 3584...\n",
      "extracing deep features from the face pair 3648...\n",
      "extracing deep features from the face pair 3712...\n",
      "extracing deep features from the face pair 3776...\n",
      "extracing deep features from the face pair 3840...\n",
      "extracing deep features from the face pair 3904...\n",
      "extracing deep features from the face pair 3968...\n",
      "extracing deep features from the face pair 4032...\n",
      "extracing deep features from the face pair 4096...\n",
      "extracing deep features from the face pair 4160...\n",
      "extracing deep features from the face pair 4224...\n",
      "extracing deep features from the face pair 4288...\n",
      "extracing deep features from the face pair 4352...\n",
      "extracing deep features from the face pair 4416...\n",
      "extracing deep features from the face pair 4480...\n",
      "extracing deep features from the face pair 4544...\n",
      "extracing deep features from the face pair 4608...\n",
      "extracing deep features from the face pair 4672...\n",
      "extracing deep features from the face pair 4736...\n",
      "extracing deep features from the face pair 4800...\n",
      "extracing deep features from the face pair 4864...\n",
      "extracing deep features from the face pair 4928...\n",
      "extracing deep features from the face pair 4992...\n",
      "extracing deep features from the face pair 5056...\n",
      "extracing deep features from the face pair 5120...\n",
      "extracing deep features from the face pair 5184...\n",
      "extracing deep features from the face pair 5248...\n",
      "extracing deep features from the face pair 5312...\n",
      "extracing deep features from the face pair 5376...\n",
      "extracing deep features from the face pair 5440...\n",
      "extracing deep features from the face pair 5504...\n",
      "extracing deep features from the face pair 5568...\n",
      "extracing deep features from the face pair 5632...\n",
      "extracing deep features from the face pair 5696...\n",
      "extracing deep features from the face pair 5760...\n",
      "extracing deep features from the face pair 5824...\n",
      "extracing deep features from the face pair 5888...\n",
      "extracing deep features from the face pair 5952...\n",
      "extracing deep features from the face pair 6000...\n",
      "1    70.83%\n",
      "2    69.83%\n",
      "3    70.50%\n",
      "4    67.67%\n",
      "5    70.00%\n",
      "6    72.17%\n",
      "7    70.00%\n",
      "8    72.00%\n",
      "9    70.67%\n",
      "10    67.83%\n",
      "--------\n",
      "AVE    70.1500%\n"
     ]
    }
   ],
   "source": [
    "test_Accuracy('./model/Training_5_Res_NLLLoss_1FC_100e_SP.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_model_test_accuracy：\n",
    "1. model 1: 66.9333\n",
    "2. model 2: 69.8000\n",
    "3. model 3: 69.7167\n",
    "4. model 4: 69.8000\n",
    "5. model 5: 70.1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_test_accuracy = [66.9333, 69.8000, 69.7167, 69.8000, 70.1500]\n",
    "all_model_test_accuracy = [x-65 for x in all_model_test_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAALw0lEQVR4nO3da4xcdR3G8edht4AK8dbRoCWsRoMSFdANxmCMIlFQoxHRgIC+0OwbSLwlxrsl0cQYowZvsCKKkUtMUIOgXAQq0chlWyq0XIRgVcCkS9QIIYKFxxdzSkuddk+3c2Z+2/1+kk1nd87O/Oaf3e+ePXtm6iQCANS1z7gHAADsGqEGgOIINQAUR6gBoDhCDQDFTXZxoytXrszU1FQXNw0Ae6W1a9c+mKQ36LpOQj01NaW5ubkubhoA9kq2/7Kz6zj0AQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMV18sxEAKjosce7/49S9p3w0G+TUANYVmZv39LZbc8c1k1SOfQBAMW1yr/tTZIekvS4pC1JprscCgCwze7sp78pyYOdTQIAGIhDHwBQXNtQR9JVttfanhm0ge0Z23O25+bn54c3IQAsc21DfXSSV0s6XtLptt+w4wZJZpNMJ5nu9Qb+JwUAgEVoFeokDzT/bpb0c0lHdTkUAGCbBUNt+xm2D9x6WdJbJG3oejAAQF+bsz6eL+nntrduf2GSKzqdCgDwpAVDneReSYePYBYAwACcngcAxRFqACiOF2VaIpbqq35hPPh62bsQ6iVkKb7qF8aHr5e9B4c+AKA4fixiSeNXfCwHhBpLHr/iY2/HoQ8AKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAojlADQHGEGgCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFtQ617Qnbt9i+rMuBAABPtTt71B+RdEdXgwAABmsVaturJL1d0rndjgMA2FHbPepvSvqkpCd2toHtGdtztufm5+eHMRsAQC1CbfsdkjYnWbur7ZLMJplOMt3r9YY2IAAsd232qI+W9E7bmyRdLOkY2z/pdCoAwJMWDHWSTydZlWRK0kmSrk1yaueTAQAkcR41AJQ3uTsbJ1kjaU0nkwAABmKPGgCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAojlADQHGEGgCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqAChuwVDb3t/2Tbb/aHuj7TNHMRgAoG+yxTaPSjomycO2V0j6ne1fJ7mh49kAAGoR6iSR9HDz7ormLV0OBQDYptUxatsTttdL2izp6iQ3Dthmxvac7bn5+fkhjwkAy1erUCd5PMkRklZJOsr2KwZsM5tkOsl0r9cb8pgAsHzt1lkfSf4laY2k47oYBgDw/9qc9dGz/azm8tMkHSvpzo7nAgA02pz1cZCk821PqB/2nya5rNuxAABbtTnr41ZJR45gFgDAADwzEQCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAojlADQHGEGgCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqAChuwVDbPtj2dbbvsL3R9kdGMRgAoG+yxTZbJH0iyTrbB0paa/vqJLd3PBsAQC32qJP8Pcm65vJDku6Q9MKuBwMA9O3WMWrbU5KOlHTjgOtmbM/Znpufnx/SeACA1qG2fYCkSyR9NMm/d7w+yWyS6STTvV5vmDMCwLLWKtS2V6gf6QuS/KzbkQAA21vwj4m2LekHku5I8vWuB3rs8XR9F9p3wp3fBwAMS5uzPo6WdJqk22yvbz72mSS/6mqo2du3dHXTmjmszUMGgDoWrFaS30liFxQAxoRnJgJAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAojlADQHGEGgCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFLRhq2+fZ3mx7wygGAgA8VZs96h9JOq7jOQAAO7FgqJNcL+kfI5gFADAAx6gBoLihhdr2jO0523Pz8/PDulkAWPaGFuoks0mmk0z3er1h3SwALHsc+gCA4tqcnneRpD9IOtT2fbY/1P1YAICtJhfaIMnJoxgEADAYhz4AoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAojlADQHGEGgCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABTXKtS2j7N9l+17bH+q66EAANssGGrbE5K+I+l4SYdJOtn2YV0PBgDoa7NHfZSke5Lcm+QxSRdLele3YwEAtnKSXW9gnyjpuCQfbt4/TdJrk5yxw3Yzkmaadw+VdNfwxx1opaQHR3RfSwnrMhjrMhjrMtgo1+WQJL1BV0y2+GQP+Nj/1T3JrKTZ3Rxsj9meSzI96vutjnUZjHUZjHUZrMq6tDn0cZ+kg7d7f5WkB7oZBwCwozahvlnSS22/yPa+kk6SdGm3YwEAtlrw0EeSLbbPkHSlpAlJ5yXZ2Plk7Y38cMsSwboMxroMxroMVmJdFvxjIgBgvHhmIgAUR6gBoLglH2rbm2yvXMw2tr9s+2+2H+5uwvFY7LrYfrrty23faXuj7a90O+lo7eHXyxW2/9isy9nNs3b3CnuyLttdf6ntDcOfbnz28OtlTfPSG+ubt+ctdo4lH+o99Ev1n3mJp/pakpdJOlLS0baPH/dARbwvyeGSXiGpJ+m9Y56nDNsnSNrrdniG4JQkRzRvmxd7IyMPte2pZm/tXNsbbF9g+1jbv7d9t+2jmu2eY/sXtm+1fYPtVzUff67tq2zfYvscbfeEHNun2r6p+el1zkJ7PEluSPL3Th9wS1XWJckjSa5rLj8maZ36586PRZV1kaQk/24uTkraVwOe+DUqldbF9gGSPi7pSx0+5FYqrctQJRnpm6QpSVskvVL9HxRrJZ3XLMi7JP2i2e5bkr7YXD5G0vrm8lmSvtBcfrv63ywrJb1c/T3kFc1135X0gebyJkkrdzHTw6NehyWyLs+SdK+kF7MuT85zpaR/SrpQ0gTrEkn6hqR3NzNt4PvoyVnWSLpN0npJn1dzlt1i3to8hbwLf05ymyTZ3ijpmiSxfZv6Cy1Jr5f0HklKcm3zk+6Zkt4g6YTm45fb/mez/ZslvUbSzbYl6WmSFv2rxpiUWRfbk5IuknRWknuH9PgWq8y6JHmr7f0lXaD+N/jVw3mIizL2dbF9hKSXJPmY7amdbTdiY1+XxilJ7rd9oKRLJJ0m6ceLeUDjCvWj211+Yrv3n9C2mXb1GiODfuW0pPOTfHooE45HpXWZlXR3km/u5ud1odK6KMl/bF+q/h7aOENdYV1eJ+k1tjc19/k822uSvLHl53ehwrooyf3Nvw/ZvlD9v4ctKtSV/5h4vaRTJMn2GyU9mP4xwu0/frykZzfbXyPpRDd/WW2OQR0y4plHofN1sf0lSc+U9NHhj9+ZTtfF9gG2D2ouT0p6m6Q7O3kkw9XpuiT5XpIXJJlSfy/1T2OOdFtdf71MujkTxPYKSe+QtOgzYsa1R93Gakk/tH2rpEckfbD5+JmSLrK9TtJvJf1VkpLcbvtzkq6yvY+k/0o6XdJfdnYHtr8q6f2Snm77PknnJlndzcMZmtXqcF1sr5L0WfUjtK75Ne/bSc7t7BENx2p1+/XyDEmX2t5P/ZdSuFbS2R09lmFarY6/j5ao1ep2XfaTdGUT6QlJv5H0/cUOy1PIAaC4yoc+AAAi1ABQHqEGgOIINQAUR6gBoDhCDQDFEWoAKO5/TK5Ix0u0gVoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "num_list = all_model_test_accuracy\n",
    "labels = ['model 1', 'model 2', 'model 3', 'model 4', 'model 5']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.bar(range(len(num_list)), num_list, alpha=0.9, width = 0.35, facecolor = 'lightskyblue', edgecolor = 'white',tick_label=labels, lw=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
